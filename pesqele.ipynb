{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3b39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros coletados (até o cap de 50): 50\n",
      "Novos nesta rodada: 50\n",
      "[{'numero_identificacao': 'RJ-03505/2024', 'eleicao': 'Eleições Municipais 2024', 'empresa_contratada': 'INSTITUTO FRANCA DE PESQUISAS LTDA / INSTITUTO FRANCA DE PESQUISA PESQUISA E ASSESSORIA', 'data_registro': '27/09/2025', 'abrangencia': 'RJ / TRÊS RIOS', 'capturado_em': '17/12/2025 15:07:59'}, {'numero_identificacao': 'BA-09599/2024', 'eleicao': 'Eleições Municipais 2024', 'empresa_contratada': 'PAINEL BRASIL CONSULTORIA E PESQUISA DE MERCADO E OPINIAO LTDA - ME / PAINEL BRASIL', 'data_registro': '12/12/2024', 'abrangencia': 'BA / RUY BARBOSA', 'capturado_em': '17/12/2025 15:07:59'}, {'numero_identificacao': 'RO-00581/2024', 'eleicao': 'Eleições Municipais 2024', 'empresa_contratada': 'INSTITUTO NOVO PERFIL PESQUISAS LTDA / PERFIL PESQUISAS', 'data_registro': '26/10/2024', 'abrangencia': 'RO / PORTO VELHO', 'capturado_em': '17/12/2025 15:07:59'}, {'numero_identificacao': 'CE-02235/2024', 'eleicao': 'Eleições Municipais 2024', 'empresa_contratada': 'INSTITUTO OPNUS DE OPINIAO E PESQUISA LTDA / INSTITUTO OPNUS', 'data_registro': '25/10/2024', 'abrangencia': 'CE / FORTALEZA', 'capturado_em': '17/12/2025 15:07:59'}, {'numero_identificacao': 'SP-07942/2024', 'eleicao': 'Eleições Municipais 2024', 'empresa_contratada': 'CELIO RICARDO SILVA DA COSTA COMUNICACAO / BADRA COMUNICACAO', 'data_registro': '22/10/2024', 'abrangencia': 'SP / SANTOS', 'capturado_em': '17/12/2025 15:07:59'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    ElementClickInterceptedException,\n",
    "    StaleElementReferenceException,\n",
    ")\n",
    "\n",
    "URL = \"https://pesqele-divulgacao.tse.jus.br/app/pesquisa/listar.xhtml\"\n",
    "\n",
    "ID_ELEICAO_LABEL = \"formPesquisa:eleicoes_label\"\n",
    "ID_ELEICAO_PANEL = \"formPesquisa:eleicoes_panel\"\n",
    "\n",
    "ID_BTN_PESQUISAR = \"formPesquisa:idBtnPesquisar\"\n",
    "\n",
    "ID_TBODY = \"formPesquisa:tabelaPesquisas_data\"\n",
    "ID_PAGINATOR = \"formPesquisa:tabelaPesquisas_paginator_bottom\"\n",
    "\n",
    "STATE_PATH = \"pesqele_seen.json\"\n",
    "\n",
    "\n",
    "def make_driver(profile_dir: str = \"./chrome-profile-pesqele\", headless: bool = False) -> webdriver.Chrome:\n",
    "    opts = webdriver.ChromeOptions()\n",
    "    opts.add_argument(\"--start-maximized\")\n",
    "    opts.add_argument(f\"--user-data-dir={os.path.abspath(profile_dir)}\")\n",
    "    if headless:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    return webdriver.Chrome(options=opts)\n",
    "\n",
    "\n",
    "def wait_dom_ready(driver: webdriver.Chrome, timeout: int = 30) -> None:\n",
    "    WebDriverWait(driver, timeout).until(\n",
    "        lambda d: d.execute_script(\"return document.readyState\") in (\"interactive\", \"complete\")\n",
    "    )\n",
    "\n",
    "\n",
    "def safe_click(driver: webdriver.Chrome, wait: WebDriverWait, by: By, value: str, timeout: int = 30):\n",
    "    el = WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((by, value)))\n",
    "    try:\n",
    "        el.click()\n",
    "        return el\n",
    "    except ElementClickInterceptedException:\n",
    "        driver.execute_script(\"arguments[0].click();\", el)\n",
    "        return el\n",
    "\n",
    "\n",
    "def select_one_menu_by_text(driver: webdriver.Chrome, wait: WebDriverWait, label_id: str, panel_id: str, text: str) -> None:\n",
    "    safe_click(driver, wait, By.ID, label_id)\n",
    "    panel = wait.until(EC.visibility_of_element_located((By.ID, panel_id)))\n",
    "    item = panel.find_element(By.XPATH, f\".//li[normalize-space()='{text}']\")\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", item)\n",
    "    item.click()\n",
    "    wait.until(EC.invisibility_of_element_located((By.ID, panel_id)))\n",
    "\n",
    "\n",
    "def click_and_wait_table_refresh(driver: webdriver.Chrome, wait: WebDriverWait, btn_id: str, tbody_id: str) -> None:\n",
    "    try:\n",
    "        old_tbody = driver.find_element(By.ID, tbody_id)\n",
    "    except Exception:\n",
    "        old_tbody = None\n",
    "\n",
    "    btn = safe_click(driver, wait, By.ID, btn_id)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", btn)\n",
    "\n",
    "    try:\n",
    "        btn.click()\n",
    "    except Exception:\n",
    "        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "\n",
    "    if old_tbody is not None:\n",
    "        try:\n",
    "            wait.until(EC.staleness_of(old_tbody))\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.ID, tbody_id)))\n",
    "\n",
    "\n",
    "def parse_current_table(driver: webdriver.Chrome, tbody_id: str) -> List[Dict[str, str]]:\n",
    "    tbody = driver.find_element(By.ID, tbody_id)\n",
    "    rows = tbody.find_elements(By.XPATH, \".//tr\")\n",
    "    out: List[Dict[str, str]] = []\n",
    "\n",
    "    for r in rows:\n",
    "        cols = [c.text.strip() for c in r.find_elements(By.XPATH, \"./td\")]\n",
    "        if len(cols) < 5:\n",
    "            continue\n",
    "        out.append({\n",
    "            \"numero_identificacao\": cols[0],\n",
    "            \"eleicao\": cols[1],\n",
    "            \"empresa_contratada\": cols[2],\n",
    "            \"data_registro\": cols[3],\n",
    "            \"abrangencia\": cols[4],\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_page_numbers(driver: webdriver.Chrome, wait: WebDriverWait, paginator_id: str) -> List[int]:\n",
    "    pag = wait.until(EC.presence_of_element_located((By.ID, paginator_id)))\n",
    "    links = pag.find_elements(By.CSS_SELECTOR, \"a.ui-paginator-page\")\n",
    "    nums = []\n",
    "    for a in links:\n",
    "        txt = (a.text or \"\").strip()\n",
    "        if txt.isdigit():\n",
    "            nums.append(int(txt))\n",
    "    return sorted(set(nums))\n",
    "\n",
    "\n",
    "def go_to_page(driver: webdriver.Chrome, wait: WebDriverWait, paginator_id: str, tbody_id: str, page_num: int) -> None:\n",
    "    pag = wait.until(EC.presence_of_element_located((By.ID, paginator_id)))\n",
    "    a = pag.find_element(By.CSS_SELECTOR, f\"a.ui-paginator-page[aria-label='Page {page_num}']\")\n",
    "\n",
    "    tbody_before = driver.find_element(By.ID, tbody_id)\n",
    "\n",
    "    try:\n",
    "        a.click()\n",
    "    except (ElementClickInterceptedException, StaleElementReferenceException):\n",
    "        driver.execute_script(\"arguments[0].click();\", a)\n",
    "\n",
    "    try:\n",
    "        wait.until(EC.staleness_of(tbody_before))\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    wait.until(EC.presence_of_element_located((By.ID, tbody_id)))\n",
    "\n",
    "\n",
    "def scrape_all_pages_current_query(driver: webdriver.Chrome, wait: WebDriverWait, paginator_id: str, tbody_id: str) -> List[Dict[str, str]]:\n",
    "    pages = get_page_numbers(driver, wait, paginator_id)\n",
    "    if not pages:\n",
    "        return parse_current_table(driver, tbody_id)\n",
    "\n",
    "    all_rows: List[Dict[str, str]] = []\n",
    "    for p in pages:\n",
    "        go_to_page(driver, wait, paginator_id, tbody_id, p)\n",
    "        all_rows.extend(parse_current_table(driver, tbody_id))\n",
    "\n",
    "    seen = set()\n",
    "    dedup = []\n",
    "    for r in all_rows:\n",
    "        k = r.get(\"numero_identificacao\")\n",
    "        if not k or k in seen:\n",
    "            continue\n",
    "        seen.add(k)\n",
    "        dedup.append(r)\n",
    "\n",
    "    return dedup\n",
    "\n",
    "\n",
    "def load_seen(path: str) -> set:\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return set(json.load(f))\n",
    "    return set()\n",
    "\n",
    "\n",
    "def save_seen(path: str, seen: set) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sorted(seen), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def run(eleicao_text: str = \"Eleições Municipais 2024\", headless: bool = False) -> List[Dict[str, str]]:\n",
    "    driver = make_driver(headless=headless)\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "\n",
    "    try:\n",
    "        driver.get(URL)\n",
    "        wait_dom_ready(driver)\n",
    "\n",
    "        select_one_menu_by_text(driver, wait, ID_ELEICAO_LABEL, ID_ELEICAO_PANEL, eleicao_text)\n",
    "        click_and_wait_table_refresh(driver, wait, ID_BTN_PESQUISAR, ID_TBODY)\n",
    "\n",
    "        rows = scrape_all_pages_current_query(driver, wait, ID_PAGINATOR, ID_TBODY)\n",
    "        return rows\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def persist_and_diff(rows: List[Dict[str, str]], state_path: str = STATE_PATH) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"capturado_em\"] = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    seen = load_seen(state_path)\n",
    "    cur = set(df[\"numero_identificacao\"].dropna().astype(str))\n",
    "\n",
    "    novos = sorted(cur - seen)\n",
    "    df_novos = df[df[\"numero_identificacao\"].isin(novos)].copy()\n",
    "\n",
    "    save_seen(state_path, seen | cur)\n",
    "    return df, df_novos\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rows = run(\"Eleições Municipais 2024\", headless=False)\n",
    "    df, df_novos = persist_and_diff(rows)\n",
    "\n",
    "    print(f\"Registros coletados (até o cap de 50): {len(df)}\")\n",
    "    print(f\"Novos nesta rodada: {len(df_novos)}\")\n",
    "\n",
    "    df.to_csv(\"pesqele_municipais_2024_last50.csv\", index=False, encoding=\"utf-8\")\n",
    "    df_novos.to_csv(\"pesqele_municipais_2024_novos.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(df.head(5).to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df03bb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLSX gerado: pesqele_elei_es_municipais_2024_por_uf_20251217_153446.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    ElementClickInterceptedException,\n",
    "    StaleElementReferenceException,\n",
    ")\n",
    "\n",
    "URL = \"https://pesqele-divulgacao.tse.jus.br/app/pesquisa/listar.xhtml\"\n",
    "\n",
    "ID_ELEICAO_LABEL = \"formPesquisa:eleicoes_label\"\n",
    "ID_ELEICAO_PANEL = \"formPesquisa:eleicoes_panel\"\n",
    "\n",
    "ID_UF_LABEL = \"formPesquisa:filtroUF_label\"\n",
    "ID_UF_PANEL = \"formPesquisa:filtroUF_panel\"\n",
    "\n",
    "ID_BTN_PESQUISAR = \"formPesquisa:idBtnPesquisar\"\n",
    "\n",
    "ID_TBODY = \"formPesquisa:tabelaPesquisas_data\"\n",
    "ID_PAGINATOR = \"formPesquisa:tabelaPesquisas_paginator_bottom\"\n",
    "\n",
    "\n",
    "def make_driver(profile_dir: str = \"./chrome-profile-pesqele\", headless: bool = False) -> webdriver.Chrome:\n",
    "    opts = webdriver.ChromeOptions()\n",
    "    opts.add_argument(\"--start-maximized\")\n",
    "    opts.add_argument(f\"--user-data-dir={os.path.abspath(profile_dir)}\")\n",
    "    if headless:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    return webdriver.Chrome(options=opts)\n",
    "\n",
    "\n",
    "def wait_dom_ready(driver: webdriver.Chrome, timeout: int = 30) -> None:\n",
    "    WebDriverWait(driver, timeout).until(\n",
    "        lambda d: d.execute_script(\"return document.readyState\") in (\"interactive\", \"complete\")\n",
    "    )\n",
    "\n",
    "\n",
    "def safe_click(driver: webdriver.Chrome, wait: WebDriverWait, by: By, value: str, timeout: int = 30):\n",
    "    el = WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((by, value)))\n",
    "    try:\n",
    "        el.click()\n",
    "        return el\n",
    "    except ElementClickInterceptedException:\n",
    "        driver.execute_script(\"arguments[0].click();\", el)\n",
    "        return el\n",
    "\n",
    "\n",
    "def force_close_any_menu(driver: webdriver.Chrome):\n",
    "    try:\n",
    "        driver.switch_to.active_element.send_keys(Keys.ESCAPE)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        driver.find_element(By.TAG_NAME, \"body\").click()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def open_menu(driver: webdriver.Chrome, wait: WebDriverWait, label_id: str, panel_id: str) -> None:\n",
    "    safe_click(driver, wait, By.ID, label_id)\n",
    "    wait.until(EC.presence_of_element_located((By.ID, panel_id)))\n",
    "    wait.until(EC.visibility_of_element_located((By.ID, panel_id)))\n",
    "\n",
    "\n",
    "def select_one_menu_by_text(driver: webdriver.Chrome, wait: WebDriverWait, label_id: str, panel_id: str, text: str) -> None:\n",
    "    open_menu(driver, wait, label_id, panel_id)\n",
    "\n",
    "    panel = driver.find_element(By.ID, panel_id)\n",
    "    item = panel.find_element(By.XPATH, f\".//li[normalize-space()='{text}']\")\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", item)\n",
    "    try:\n",
    "        item.click()\n",
    "    except Exception:\n",
    "        driver.execute_script(\"arguments[0].click();\", item)\n",
    "\n",
    "    force_close_any_menu(driver)\n",
    "\n",
    "\n",
    "def list_one_menu_items(driver: webdriver.Chrome, wait: WebDriverWait, label_id: str, panel_id: str) -> List[str]:\n",
    "    open_menu(driver, wait, label_id, panel_id)\n",
    "\n",
    "    panel = driver.find_element(By.ID, panel_id)\n",
    "    lis = panel.find_elements(By.CSS_SELECTOR, \"li.ui-selectonemenu-item\")\n",
    "\n",
    "    items = []\n",
    "    for li in lis:\n",
    "        t = (li.text or \"\").strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        if t.lower() in {\"selecione\"}:\n",
    "            continue\n",
    "        items.append(t)\n",
    "\n",
    "    force_close_any_menu(driver)\n",
    "    return items\n",
    "\n",
    "\n",
    "def click_and_wait_table_refresh(driver: webdriver.Chrome, wait: WebDriverWait, btn_id: str, tbody_id: str) -> None:\n",
    "    try:\n",
    "        old_tbody = driver.find_element(By.ID, tbody_id)\n",
    "    except Exception:\n",
    "        old_tbody = None\n",
    "\n",
    "    btn = safe_click(driver, wait, By.ID, btn_id)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", btn)\n",
    "    try:\n",
    "        btn.click()\n",
    "    except Exception:\n",
    "        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "\n",
    "    if old_tbody is not None:\n",
    "        try:\n",
    "            wait.until(EC.staleness_of(old_tbody))\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "\n",
    "    wait.until(EC.presence_of_element_located((By.ID, tbody_id)))\n",
    "\n",
    "\n",
    "def parse_current_table(driver: webdriver.Chrome, tbody_id: str) -> List[Dict[str, str]]:\n",
    "    tbody = driver.find_element(By.ID, tbody_id)\n",
    "    rows = tbody.find_elements(By.XPATH, \".//tr\")\n",
    "\n",
    "    out: List[Dict[str, str]] = []\n",
    "    for r in rows:\n",
    "        cols = [c.text.strip() for c in r.find_elements(By.XPATH, \"./td\")]\n",
    "        if len(cols) < 5:\n",
    "            continue\n",
    "        out.append({\n",
    "            \"numero_identificacao\": cols[0],\n",
    "            \"eleicao\": cols[1],\n",
    "            \"empresa_contratada\": cols[2],\n",
    "            \"data_registro\": cols[3],\n",
    "            \"abrangencia\": cols[4],\n",
    "        })\n",
    "    return out\n",
    "\n",
    "\n",
    "def dedup_by_numero(rows: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        k = (r.get(\"numero_identificacao\") or \"\").strip()\n",
    "        if not k or k in seen:\n",
    "            continue\n",
    "        seen.add(k)\n",
    "        out.append(r)\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_page_numbers(driver: webdriver.Chrome, wait: WebDriverWait, paginator_id: str) -> List[int]:\n",
    "    pag = wait.until(EC.presence_of_element_located((By.ID, paginator_id)))\n",
    "    links = pag.find_elements(By.CSS_SELECTOR, \"a.ui-paginator-page\")\n",
    "\n",
    "    nums = []\n",
    "    for a in links:\n",
    "        txt = (a.text or \"\").strip()\n",
    "        if txt.isdigit():\n",
    "            nums.append(int(txt))\n",
    "\n",
    "    return sorted(set(nums))\n",
    "\n",
    "\n",
    "def go_to_page(driver: webdriver.Chrome, wait: WebDriverWait, paginator_id: str, tbody_id: str, page_num: int, max_tries: int = 6) -> None:\n",
    "    last_err = None\n",
    "\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            pag = wait.until(EC.presence_of_element_located((By.ID, paginator_id)))\n",
    "\n",
    "            # Re-localiza SEMPRE (pra não ficar stale)\n",
    "            a = pag.find_element(By.CSS_SELECTOR, f\"a.ui-paginator-page[aria-label='Page {page_num}']\")\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", a)\n",
    "\n",
    "            tbody_before = driver.find_element(By.ID, tbody_id)\n",
    "\n",
    "            # JS click tende a ser mais estável em PrimeFaces\n",
    "            driver.execute_script(\"arguments[0].click();\", a)\n",
    "\n",
    "            try:\n",
    "                wait.until(EC.staleness_of(tbody_before))\n",
    "            except TimeoutException:\n",
    "                pass\n",
    "\n",
    "            wait.until(EC.presence_of_element_located((By.ID, tbody_id)))\n",
    "\n",
    "            # Confirma que a página ficou ativa (a ou span, depende da renderização)\n",
    "            try:\n",
    "                wait.until(EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, f\"a.ui-paginator-page.ui-state-active[aria-label='Page {page_num}']\")\n",
    "                ))\n",
    "            except TimeoutException:\n",
    "                try:\n",
    "                    wait.until(EC.presence_of_element_located(\n",
    "                        (By.CSS_SELECTOR, f\"span.ui-paginator-page.ui-state-active[aria-label='Page {page_num}']\")\n",
    "                    ))\n",
    "                except TimeoutException:\n",
    "                    pass\n",
    "\n",
    "            return\n",
    "\n",
    "        except (StaleElementReferenceException, ElementClickInterceptedException, TimeoutException) as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    raise last_err\n",
    "\n",
    "\n",
    "def scrape_all_pages_current_query(driver: webdriver.Chrome, wait: WebDriverWait, paginator_id: str, tbody_id: str) -> List[Dict[str, str]]:\n",
    "    pages = get_page_numbers(driver, wait, paginator_id)\n",
    "    if not pages:\n",
    "        return dedup_by_numero(parse_current_table(driver, tbody_id))\n",
    "\n",
    "    all_rows: List[Dict[str, str]] = []\n",
    "    for p in pages:\n",
    "        go_to_page(driver, wait, paginator_id, tbody_id, p)\n",
    "        all_rows.extend(parse_current_table(driver, tbody_id))\n",
    "\n",
    "    return dedup_by_numero(all_rows)\n",
    "\n",
    "\n",
    "def sheet_safe(name: str) -> str:\n",
    "    s = re.sub(r\"[\\[\\]\\:\\*\\?\\/\\\\]\", \"-\", name.strip())\n",
    "    return s[:31] if len(s) > 31 else s\n",
    "\n",
    "\n",
    "def run_by_uf(eleicao_text: str = \"Eleições Municipais 2024\", headless: bool = False) -> str:\n",
    "    driver = make_driver(headless=headless)\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", eleicao_text).strip(\"_\").lower()\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_xlsx = f\"pesqele_{slug}_por_uf_{ts}.xlsx\"\n",
    "\n",
    "    dfs: Dict[str, pd.DataFrame] = {}\n",
    "    resumo: List[Dict[str, str]] = []\n",
    "\n",
    "    try:\n",
    "        driver.get(URL)\n",
    "        wait_dom_ready(driver)\n",
    "\n",
    "        select_one_menu_by_text(driver, wait, ID_ELEICAO_LABEL, ID_ELEICAO_PANEL, eleicao_text)\n",
    "\n",
    "        ufs = list_one_menu_items(driver, wait, ID_UF_LABEL, ID_UF_PANEL)\n",
    "        ufs = [u for u in ufs if u.upper() != \"BRASIL\"]\n",
    "\n",
    "        for uf in ufs:\n",
    "            try:\n",
    "                select_one_menu_by_text(driver, wait, ID_UF_LABEL, ID_UF_PANEL, uf)\n",
    "\n",
    "                click_and_wait_table_refresh(driver, wait, ID_BTN_PESQUISAR, ID_TBODY)\n",
    "                rows = scrape_all_pages_current_query(driver, wait, ID_PAGINATOR, ID_TBODY)\n",
    "\n",
    "                df = pd.DataFrame(rows)\n",
    "                df[\"uf_filtro\"] = uf\n",
    "                df[\"capturado_em\"] = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "                dfs[uf] = df\n",
    "\n",
    "                resumo.append({\n",
    "                    \"uf\": uf,\n",
    "                    \"status\": \"ok\",\n",
    "                    \"linhas\": str(len(df)),\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                resumo.append({\n",
    "                    \"uf\": uf,\n",
    "                    \"status\": \"erro\",\n",
    "                    \"linhas\": \"0\",\n",
    "                    \"erro\": repr(e)[:300],\n",
    "                })\n",
    "\n",
    "        # Sempre escreve pelo menos o __resumo__ (evita \"At least one sheet must be visible\")\n",
    "        df_resumo = pd.DataFrame(resumo).sort_values([\"status\", \"uf\"], ascending=[True, True])\n",
    "\n",
    "        with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "            df_resumo.to_excel(writer, sheet_name=\"__resumo__\", index=False)\n",
    "\n",
    "            for uf, df in dfs.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_safe(uf), index=False)\n",
    "\n",
    "        return out_xlsx\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = run_by_uf(eleicao_text=\"Eleições Municipais 2024\", headless=False)\n",
    "    print(f\"XLSX gerado: {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
